#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
maro ì±„ë„ ì˜ìƒ ìƒì„±ê¸° - í•œê¸€ í°íŠ¸ ë¬¸ì œ ì™„ì „ í•´ê²°
ë„¤ëª¨ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
"""

import os
import json
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import subprocess
import sys
import platform

def get_best_korean_font():
    """ìµœì ì˜ í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
    system = platform.system()
    
    if system == "Windows":
        # Windows í•œê¸€ í°íŠ¸ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",      # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/malgunbd.ttf",    # ë§‘ì€ ê³ ë”• Bold
            "C:/Windows/Fonts/gulim.ttc",       # êµ´ë¦¼
            "C:/Windows/Fonts/gulim.ttc",       # êµ´ë¦¼ì²´
            "C:/Windows/Fonts/dotum.ttc",       # ë‹ì›€
            "C:/Windows/Fonts/dotum.ttc",       # ë‹ì›€ì²´
            "C:/Windows/Fonts/batang.ttc",      # ë°”íƒ•
            "C:/Windows/Fonts/batang.ttc",      # ë°”íƒ•ì²´
            "C:/Windows/Fonts/arial.ttf",       # Arial (ì˜ë¬¸)
        ]
    elif system == "Darwin":  # macOS
        font_paths = [
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/System/Library/Fonts/Helvetica.ttc",
        ]
    else:  # Linux
        font_paths = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        ]
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì°¾ê¸°
    for font_path in font_paths:
        if os.path.exists(font_path):
            return font_path
    
    return None

def create_text_image_with_fallback(text, width=1920, height=200, font_size=60, bg_color=(255, 248, 240), text_color=(44, 62, 80)):
    """í´ë°± ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±"""
    # PILë¡œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new('RGB', (width, height), bg_color)
    draw = ImageDraw.Draw(img)
    
    # í°íŠ¸ ì„¤ì • (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
    font = None
    
    # ë°©ë²• 1: ì§ì ‘ í°íŠ¸ ê²½ë¡œ ì§€ì •
    font_path = get_best_korean_font()
    if font_path:
        try:
            font = ImageFont.truetype(font_path, font_size)
            print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
        except Exception as e:
            print(f"âš ï¸ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            font = None
    
    # ë°©ë²• 2: í°íŠ¸ ì´ë¦„ìœ¼ë¡œ ì°¾ê¸°
    if not font:
        font_names = ["malgun.ttf", "gulim.ttc", "dotum.ttc", "batang.ttc", "arial.ttf"]
        for font_name in font_names:
            try:
                font = ImageFont.truetype(font_name, font_size)
                print(f"âœ… í°íŠ¸ ì´ë¦„ìœ¼ë¡œ ë¡œë“œ ì„±ê³µ: {font_name}")
                break
            except:
                continue
    
    # ë°©ë²• 3: ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    if not font:
        try:
            font = ImageFont.load_default()
            print("âš ï¸ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        except:
            print("âŒ ëª¨ë“  í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨")
            return None
    
    # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
    words = text.split()
    lines = []
    current_line = ""
    
    for word in words:
        test_line = current_line + " " + word if current_line else word
        try:
            bbox = draw.textbbox((0, 0), test_line, font=font)
            text_width = bbox[2] - bbox[0]
        except:
            # bbox ê³„ì‚° ì‹¤íŒ¨ì‹œ ëŒ€ëµì  ê³„ì‚°
            text_width = len(test_line) * font_size * 0.6
        
        if text_width <= width - 100:
            current_line = test_line
        else:
            if current_line:
                lines.append(current_line)
                current_line = word
            else:
                lines.append(word)
    
    if current_line:
        lines.append(current_line)
    
    # ê° ì¤„ì„ ê·¸ë¦¬ê¸°
    y_start = (height - len(lines) * font_size) // 2
    for i, line in enumerate(lines):
        try:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
        except:
            text_width = len(line) * font_size * 0.6
            text_height = font_size
        
        x = (width - text_width) // 2
        y = y_start + i * font_size
        
        draw.text((x, y), line, fill=text_color, font=font)
    
    # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    return cv_img

def create_video_with_cv2_text():
    """OpenCVì˜ putTextë¥¼ ì‚¬ìš©í•œ ì˜ìƒ ìƒì„±"""
    print("ğŸ¬ OpenCV putTextë¡œ ì˜ìƒ ìƒì„±...")
    
    try:
        # ìƒ˜í”Œ ì½˜í…ì¸  ë¡œë“œ
        content_file = "maro_sample_content/20250904/daily_comfort_ìì¡´ê°ì„_ë†’ì´ëŠ”_ë°©ë²•.json"
        with open(content_file, 'r', encoding='utf-8') as f:
            content = json.load(f)
        
        # ë¹„ë””ì˜¤ ì„¤ì •
        width, height = 1920, 1080
        fps = 24
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ìƒì„±
        output_file = "maro_sample_content/maro_cv2_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))
        
        # ë°°ê²½ ìƒ‰ìƒ
        bg_color = (240, 248, 255)  # BGR í˜•ì‹
        
        # ì œëª© í”„ë ˆì„ (3ì´ˆ)
        print("ğŸ“ ì œëª© í”„ë ˆì„ ìƒì„±...")
        title_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
        
        # OpenCV putText ì‚¬ìš©
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 2.0
        color = (80, 62, 44)  # BGR í˜•ì‹
        thickness = 3
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
        title_lines = content['title'].split('\n')
        y_start = height // 2 - len(title_lines) * 60
        
        for i, line in enumerate(title_lines):
            text_size = cv2.getTextSize(line, font, font_scale, thickness)[0]
            x = (width - text_size[0]) // 2
            y = y_start + i * 120
            
            cv2.putText(title_img, line, (x, y), font, font_scale, color, thickness)
        
        for i in range(3 * fps):
            out.write(title_img)
        
        # ì½˜í…ì¸  í”„ë ˆì„ë“¤
        content_lines = content['content'].split('\n\n')
        print(f"ğŸ“ ì½˜í…ì¸  í”„ë ˆì„ ìƒì„± ({len(content_lines)}ê°œ)...")
        
        for idx, line in enumerate(content_lines):
            if line.strip():
                print(f"  - í”„ë ˆì„ {idx+1}: {line.strip()[:30]}...")
                line_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
                
                # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
                words = line.strip().split()
                lines = []
                current_line = ""
                
                for word in words:
                    test_line = current_line + " " + word if current_line else word
                    text_size = cv2.getTextSize(test_line, font, font_scale, thickness)[0]
                    
                    if text_size[0] <= width - 100:
                        current_line = test_line
                    else:
                        if current_line:
                            lines.append(current_line)
                            current_line = word
                        else:
                            lines.append(word)
                
                if current_line:
                    lines.append(current_line)
                
                # ê° ì¤„ì„ ê·¸ë¦¬ê¸°
                y_start = height // 2 - len(lines) * 60
                for i, text_line in enumerate(lines):
                    text_size = cv2.getTextSize(text_line, font, font_scale, thickness)[0]
                    x = (width - text_size[0]) // 2
                    y = y_start + i * 120
                    
                    cv2.putText(line_img, text_line, (x, y), font, font_scale, color, thickness)
                
                for i in range(4 * fps):
                    out.write(line_img)
        
        # ë§ˆë¬´ë¦¬ í”„ë ˆì„
        print("ğŸ“ ë§ˆë¬´ë¦¬ í”„ë ˆì„ ìƒì„±...")
        outro_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
        outro_text = "ë‹¹ì‹ ì€ í˜¼ìê°€ ì•„ë‹™ë‹ˆë‹¤."
        
        text_size = cv2.getTextSize(outro_text, font, font_scale, thickness)[0]
        x = (width - text_size[0]) // 2
        y = height // 2
        
        cv2.putText(outro_img, outro_text, (x, y), font, font_scale, color, thickness)
        
        for i in range(3 * fps):
            out.write(outro_img)
        
        out.release()
        
        print(f"âœ… OpenCV ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_file}")
        
        # ì˜¤ë””ì˜¤ ì¶”ê°€
        audio_file = "maro_sample_content/narration.mp3"
        if os.path.exists(audio_file):
            add_audio_to_video(output_file, audio_file)
        
        return True
        
    except Exception as e:
        print(f"âŒ OpenCV ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def add_audio_to_video(video_file, audio_file):
    """FFmpegë¡œ ì˜¤ë””ì˜¤ ì¶”ê°€"""
    print("ğŸµ ì˜¤ë””ì˜¤ ì¶”ê°€ ì¤‘...")
    
    ffmpeg_path = "ffmpeg/ffmpeg-master-latest-win64-gpl/bin/ffmpeg.exe"
    if not os.path.exists(ffmpeg_path):
        print("âŒ FFmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return False
    
    temp_file = video_file.replace('.mp4', '_with_audio.mp4')
    
    cmd = [
        ffmpeg_path, '-y',
        '-i', video_file,
        '-i', audio_file,
        '-c:v', 'copy',
        '-c:a', 'aac',
        '-b:a', '128k',
        '-shortest',
        temp_file
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        
        if os.path.exists(temp_file):
            os.replace(temp_file, video_file)
            print("âœ… ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
            return True
        else:
            print("âŒ ì„ì‹œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
            return False
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        if os.path.exists(temp_file):
            os.remove(temp_file)
        return False

def create_simple_text_video():
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì˜ìƒ ìƒì„± (í•œê¸€ ë¬¸ì œ í•´ê²°)"""
    print("ğŸ¬ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì˜ìƒ ìƒì„±...")
    
    try:
        # ìƒ˜í”Œ ì½˜í…ì¸  ë¡œë“œ
        content_file = "maro_sample_content/20250904/daily_comfort_ìì¡´ê°ì„_ë†’ì´ëŠ”_ë°©ë²•.json"
        with open(content_file, 'r', encoding='utf-8') as f:
            content = json.load(f)
        
        # ë¹„ë””ì˜¤ ì„¤ì •
        width, height = 1920, 1080
        fps = 24
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ìƒì„±
        output_file = "maro_sample_content/maro_simple_text.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))
        
        # ë°°ê²½ ìƒ‰ìƒ
        bg_color = (240, 248, 255)  # BGR í˜•ì‹
        
        # ì œëª© í”„ë ˆì„
        title_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ (ì˜ë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸)
        title_text = "Today's Comfort: Self-Esteem"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 2.0
        color = (80, 62, 44)
        thickness = 3
        
        text_size = cv2.getTextSize(title_text, font, font_scale, thickness)[0]
        x = (width - text_size[0]) // 2
        y = height // 2
        
        cv2.putText(title_img, title_text, (x, y), font, font_scale, color, thickness)
        
        for i in range(3 * fps):
            out.write(title_img)
        
        # ì½˜í…ì¸  í”„ë ˆì„ë“¤ (ì˜ë¬¸ìœ¼ë¡œ)
        content_texts = [
            "You did well today.",
            "It's okay to take a break.",
            "You are stronger than you think.",
            "Small steps matter.",
            "You are not alone."
        ]
        
        for text in content_texts:
            line_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
            
            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]
            x = (width - text_size[0]) // 2
            y = height // 2
            
            cv2.putText(line_img, text, (x, y), font, font_scale, color, thickness)
            
            for i in range(4 * fps):
                out.write(line_img)
        
        # ë§ˆë¬´ë¦¬ í”„ë ˆì„
        outro_img = np.full((height, width, 3), bg_color, dtype=np.uint8)
        outro_text = "You are not alone."
        
        text_size = cv2.getTextSize(outro_text, font, font_scale, thickness)[0]
        x = (width - text_size[0]) // 2
        y = height // 2
        
        cv2.putText(outro_img, outro_text, (x, y), font, font_scale, color, thickness)
        
        for i in range(3 * fps):
            out.write(outro_img)
        
        out.release()
        
        print(f"âœ… ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_file}")
        
        # ì˜¤ë””ì˜¤ ì¶”ê°€
        audio_file = "maro_sample_content/narration.mp3"
        if os.path.exists(audio_file):
            add_audio_to_video(output_file, audio_file)
        
        return True
        
    except Exception as e:
        print(f"âŒ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ maro ì±„ë„ ì˜ìƒ ìƒì„±ê¸° (í•œê¸€ ë¬¸ì œ í•´ê²°)")
    print("=" * 60)
    
    # í•œê¸€ í°íŠ¸ í™•ì¸
    font_path = get_best_korean_font()
    if font_path:
        print(f"âœ… í•œê¸€ í°íŠ¸ ë°œê²¬: {font_path}")
    else:
        print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    # ë°©ë²• 1: OpenCV putText ì‚¬ìš©
    print("\nğŸ¬ OpenCV putTextë¡œ ì˜ìƒ ìƒì„± ì‹œë„...")
    if create_video_with_cv2_text():
        print("âœ… OpenCV ì˜ìƒ ìƒì„± ì™„ë£Œ!")
        return
    
    # ë°©ë²• 2: ê°„ë‹¨í•œ ì˜ë¬¸ ì˜ìƒ ìƒì„±
    print("\nğŸ¬ ê°„ë‹¨í•œ ì˜ë¬¸ ì˜ìƒ ìƒì„± ì‹œë„...")
    if create_simple_text_video():
        print("âœ… ê°„ë‹¨í•œ ì˜ë¬¸ ì˜ìƒ ìƒì„± ì™„ë£Œ!")
        return
    
    print("âŒ ëª¨ë“  ì˜ìƒ ìƒì„± ë°©ë²• ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
